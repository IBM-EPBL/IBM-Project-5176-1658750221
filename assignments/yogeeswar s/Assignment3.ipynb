{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting Google Drive**"
      ],
      "metadata": {
        "id": "hHq-QSruZZRB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIuVu5r9Lrfa",
        "outputId": "06f29fb0-0b1f-4cf5-c98f-5e0e2e0bacee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,\n",
        "                                 zoom_range=0.2,horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "g0_6XaVgOEsO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"gdrive/MyDrive/Dataset/Flowers-Dataset.zip\" -d \"gdrive/MyDrive/Dataset/Flowers\""
      ],
      "metadata": {
        "id": "wsga3hQ3Tx51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMAGE AGUMENTATION**"
      ],
      "metadata": {
        "id": "1ZlXh4sRaEwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_datagen.flow_from_directory('gdrive/MyDrive/Dataset/Flowers/flowers',\n",
        "                                       target_size=(64,64),\n",
        "                                       class_mode='categorical',\n",
        "                                       batch_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbLtYH-yNXOn",
        "outputId": "e39d280a-fd1e-4a3c-ace0-9b2d669139bb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4317 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=test_datagen.flow_from_directory(\"gdrive/MyDrive/Dataset/Flowers/flowers\",target_size=(64,64),class_mode='categorical',batch_size=24)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8gl0bOwUZCZ",
        "outputId": "236b232d-83e4-4d59-d094-6ca9c9eff79b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4317 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCaUlaxbUweA",
        "outputId": "10f5552e-8423-48b2-9f9d-7c0b39e0ea8b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Dense, Flatten\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "rTEasaedPNT7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INITIALISING AND CREATING MODEL**"
      ],
      "metadata": {
        "id": "eRJIgxmfZ20m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(300,activation='relu'))\n",
        "model.add(Dense(150,activation='relu'))\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34U_wDBzPQu8",
        "outputId": "711061f4-10ac-4488-dd93-f20b76d060ee"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 31, 31, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 30752)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 300)               9225900   \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 150)               45150     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 755       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,272,701\n",
            "Trainable params: 9,272,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hIMTv_nYPSi7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAIN THE MODEL**"
      ],
      "metadata": {
        "id": "Dj72YINEZx4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(x_train,steps_per_epoch=len(x_train), validation_data=x_test, validation_steps=len(x_test), epochs= 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yROmoY2fPXPw",
        "outputId": "d843fbcd-0693-4b0b-bcae-cade6f227ed1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "44/44 [==============================] - 33s 757ms/step - loss: 1.5813 - accuracy: 0.3498 - val_loss: 1.3037 - val_accuracy: 0.4700\n",
            "Epoch 2/30\n",
            "44/44 [==============================] - 33s 747ms/step - loss: 1.1306 - accuracy: 0.5365 - val_loss: 1.0695 - val_accuracy: 0.5805\n",
            "Epoch 3/30\n",
            "44/44 [==============================] - 34s 787ms/step - loss: 1.0306 - accuracy: 0.5921 - val_loss: 1.0512 - val_accuracy: 0.5930\n",
            "Epoch 4/30\n",
            "44/44 [==============================] - 34s 780ms/step - loss: 0.9852 - accuracy: 0.6134 - val_loss: 1.0691 - val_accuracy: 0.6018\n",
            "Epoch 5/30\n",
            "44/44 [==============================] - 35s 794ms/step - loss: 0.9165 - accuracy: 0.6458 - val_loss: 0.8945 - val_accuracy: 0.6609\n",
            "Epoch 6/30\n",
            "44/44 [==============================] - 33s 757ms/step - loss: 0.8880 - accuracy: 0.6546 - val_loss: 0.9274 - val_accuracy: 0.6637\n",
            "Epoch 7/30\n",
            "44/44 [==============================] - 33s 748ms/step - loss: 0.8100 - accuracy: 0.6921 - val_loss: 0.8398 - val_accuracy: 0.6796\n",
            "Epoch 8/30\n",
            "44/44 [==============================] - 32s 746ms/step - loss: 0.7796 - accuracy: 0.6989 - val_loss: 0.7845 - val_accuracy: 0.7030\n",
            "Epoch 9/30\n",
            "44/44 [==============================] - 33s 763ms/step - loss: 0.7561 - accuracy: 0.7093 - val_loss: 0.7508 - val_accuracy: 0.7227\n",
            "Epoch 10/30\n",
            "44/44 [==============================] - 33s 751ms/step - loss: 0.7429 - accuracy: 0.7220 - val_loss: 0.7751 - val_accuracy: 0.7060\n",
            "Epoch 11/30\n",
            "44/44 [==============================] - 33s 752ms/step - loss: 0.7028 - accuracy: 0.7345 - val_loss: 0.5958 - val_accuracy: 0.7790\n",
            "Epoch 12/30\n",
            "44/44 [==============================] - 32s 738ms/step - loss: 0.6533 - accuracy: 0.7496 - val_loss: 0.6032 - val_accuracy: 0.7730\n",
            "Epoch 13/30\n",
            "44/44 [==============================] - 33s 755ms/step - loss: 0.6373 - accuracy: 0.7667 - val_loss: 0.5529 - val_accuracy: 0.7906\n",
            "Epoch 14/30\n",
            "44/44 [==============================] - 34s 772ms/step - loss: 0.6043 - accuracy: 0.7744 - val_loss: 0.5097 - val_accuracy: 0.8117\n",
            "Epoch 15/30\n",
            "44/44 [==============================] - 32s 739ms/step - loss: 0.5763 - accuracy: 0.7864 - val_loss: 0.5919 - val_accuracy: 0.7723\n",
            "Epoch 16/30\n",
            "44/44 [==============================] - 32s 740ms/step - loss: 0.5494 - accuracy: 0.7982 - val_loss: 0.5028 - val_accuracy: 0.8172\n",
            "Epoch 17/30\n",
            "44/44 [==============================] - 32s 734ms/step - loss: 0.5265 - accuracy: 0.8084 - val_loss: 0.5952 - val_accuracy: 0.7748\n",
            "Epoch 18/30\n",
            "44/44 [==============================] - 32s 735ms/step - loss: 0.5357 - accuracy: 0.8019 - val_loss: 0.6269 - val_accuracy: 0.7751\n",
            "Epoch 19/30\n",
            "44/44 [==============================] - 33s 759ms/step - loss: 0.5097 - accuracy: 0.8145 - val_loss: 0.5241 - val_accuracy: 0.8087\n",
            "Epoch 20/30\n",
            "44/44 [==============================] - 32s 731ms/step - loss: 0.4625 - accuracy: 0.8309 - val_loss: 0.3852 - val_accuracy: 0.8573\n",
            "Epoch 21/30\n",
            "44/44 [==============================] - 32s 738ms/step - loss: 0.4664 - accuracy: 0.8214 - val_loss: 0.3628 - val_accuracy: 0.8742\n",
            "Epoch 22/30\n",
            "44/44 [==============================] - 32s 736ms/step - loss: 0.4105 - accuracy: 0.8501 - val_loss: 0.3466 - val_accuracy: 0.8763\n",
            "Epoch 23/30\n",
            "44/44 [==============================] - 39s 888ms/step - loss: 0.4005 - accuracy: 0.8524 - val_loss: 0.3591 - val_accuracy: 0.8638\n",
            "Epoch 24/30\n",
            "44/44 [==============================] - 32s 725ms/step - loss: 0.3829 - accuracy: 0.8663 - val_loss: 0.3326 - val_accuracy: 0.8846\n",
            "Epoch 25/30\n",
            "44/44 [==============================] - 32s 725ms/step - loss: 0.3935 - accuracy: 0.8615 - val_loss: 0.3154 - val_accuracy: 0.8816\n",
            "Epoch 26/30\n",
            "44/44 [==============================] - 32s 724ms/step - loss: 0.3898 - accuracy: 0.8619 - val_loss: 0.3778 - val_accuracy: 0.8571\n",
            "Epoch 27/30\n",
            "44/44 [==============================] - 32s 724ms/step - loss: 0.3607 - accuracy: 0.8668 - val_loss: 0.2914 - val_accuracy: 0.8874\n",
            "Epoch 28/30\n",
            "44/44 [==============================] - 33s 755ms/step - loss: 0.3324 - accuracy: 0.8833 - val_loss: 0.3271 - val_accuracy: 0.8828\n",
            "Epoch 29/30\n",
            "44/44 [==============================] - 31s 723ms/step - loss: 0.3185 - accuracy: 0.8867 - val_loss: 0.1992 - val_accuracy: 0.9312\n",
            "Epoch 30/30\n",
            "44/44 [==============================] - 32s 728ms/step - loss: 0.3090 - accuracy: 0.8937 - val_loss: 0.2367 - val_accuracy: 0.9164\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe7c0168dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE THE MODEL**"
      ],
      "metadata": {
        "id": "GzVWwhJZZse8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('gdrive/MyDrive/Dataset/Flowers/flower_cnn.h5')"
      ],
      "metadata": {
        "id": "WHDNqX9tPY2o"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST THE MODEL**"
      ],
      "metadata": {
        "id": "y8RoTKORZiMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "m2BK7q37S4MR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=load_model('gdrive/MyDrive/Dataset/Flowers/flower_cnn.h5')"
      ],
      "metadata": {
        "id": "HKcH5AwDVcO3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = list(x_train.class_indices.keys())\n",
        "val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jx0zQHvS7j5",
        "outputId": "cc6789df-5264-4d83-9ea1-d0d81a5ddf0d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=image.load_img(r\"gdrive/MyDrive/Dataset/Flowers/flowers/dandelion/160456948_38c3817c6a_m.jpg\",target_size=(64,64))\n",
        "x=image.img_to_array(img)\n",
        "x=np.expand_dims(x,axis=0)\n",
        "y=np.argmax(model.predict(x),axis=1)\n",
        "\n",
        "index=['daisy','dandelion','rose','sunflower','tulip']\n",
        "index[y[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wl4XFrpkVijX",
        "outputId": "76630ccc-a8e3-4910-b701-ae4996b6770d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dandelion'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}